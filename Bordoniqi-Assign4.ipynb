{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b66360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/gentabordoniqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gentabordoniqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gentabordoniqi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gentabordoniqi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk.corpus\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import regex as re\n",
    "import string\n",
    "import os\n",
    "\n",
    "\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "#In summary column \n",
    "#perform tokenization \n",
    "#perform stemming \n",
    "#perform lemmatization\n",
    "\n",
    "\n",
    "data = pd.read_csv(f'{os.getcwd()}/data/Musical_instruments_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fceef6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10261 clean tokens\n",
      "Here are a subset of clean Tokens \n",
      " [['good'], ['jake'], ['job', 'well'], ['good', 'windscreen', 'money'], ['pop', 'record', 'vocal'], ['best', 'cabl'], ['monster', 'standard', '100', '21', 'instrument', 'cabl'], ['didnt', 'fit', '1996', 'fender', 'strat'], ['great', 'cabl'], ['best', 'instrument', 'cabl', 'market']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "stem = SnowballStemmer('english')\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "punkt = re.compile(f\"[{string.punctuation}]\") \n",
    "\n",
    "def preprocess(sent,stopwords,punkt):\n",
    "    \n",
    "    #remove punctuation\n",
    "    prep_sent = re.sub(punkt,\"\",sent)\n",
    "    \n",
    "\n",
    "    #Remove stopwords and lower case\n",
    "    prep_sent = ' '.join([ w for w in prep_sent.lower().split() if w not in stopwords])\n",
    " \n",
    "    #Lemmatize \n",
    "    prep_sent = ' '.join([lemma.lemmatize(w) for w in prep_sent.split()])\n",
    "    \n",
    "    #stem \n",
    "    prep_sent = ' '.join([stem.stem(w) for w in prep_sent.split()])\n",
    "    \n",
    "    return prep_sent\n",
    "    \n",
    "\n",
    "data['clean_summary'] = data['summary'].apply(lambda x: preprocess(x,stop_words,punkt))\n",
    "\n",
    "\n",
    "#tokenize clean summary \n",
    "\n",
    "data['token_clean_summary']= data['clean_summary'].apply(word_tokenize)\n",
    "\n",
    "#Append all the tokenized words in one list\n",
    "\n",
    "list_of_clean_tokens = data['token_clean_summary'].to_list()\n",
    "\n",
    "print(f'There are {len(list_of_clean_tokens)} clean tokens')\n",
    "print(f'Here are a subset of clean Tokens \\n {list_of_clean_tokens[0:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42512e2c-4559-42e4-a628-bb97f5dc8cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
